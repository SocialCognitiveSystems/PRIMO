{
 "metadata": {
  "name": "",
  "signature": "sha256:90a9d74d92118f490bf4db28493687c0ede1b81b9e3ca489862c92c0251b285e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Naive Bayes + Evidenztheorie</h1>\n",
      "<p>\n",
      "Mit dem Naive Bayes-Klassifikator, welcher um die Evidenztheorie (Dempster-Shafer) erweitert wurde, k\u00f6nnen Evidenzen mit einer Unsicherheit angegeben werden. Ist eine Evidenz nicht sicher oder soll sie als weniger wichtig interpretiert werden, kann sie mit einer `confidence` aus dem Wertebereich `[0.0, 1.0]` versehen werden.\n",
      "</p>\n",
      "<p>\n",
      "Im folgenden Beispiel wird ein Klassifikator erstellt, welcher anhand einiger technischer Features einen Gegenstand erkennen soll. Durch die Berechnung der Entropie kann eine Annahme dar\u00fcber getroffen werden, welches Feature im Mittel die Entropie des Wurzelknoten am weitesten einschr\u00e4nkt und somit am ehesten zu einer sicheren Klassifikation f\u00fchrt.\n",
      "</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import numpy\n",
      "import primo.NaiveBayesDS as NBDS\n",
      "\n",
      "# NaiveBayesDS initialisieren\n",
      "nb = NBDS.NaiveBayesDS()\n",
      "\n",
      "# Knoten:\n",
      "# Index 0: Name des Knoten\n",
      "# Index 1: Werte/Zust\u00e4nde des Knoten\n",
      "# Index 2 (Wurzelknoten): Verteilung \u00fcber Zust\u00e4nde\n",
      "# Index 2 (Featureknoten): Vom Wurzelknoten abh\u00e4ngige Wahrscheinlichkeiten, \u00e4hnlich wie CPT bei komplexeren Bayesnetzen\n",
      "\n",
      "# Wurzelknoten\n",
      "rootNode = (\"gegenstand\", [\"server\", \"laptop\", \"smartphone\", \"fernseher\", \"akkuschrauber\"], numpy.array([0.2, 0.2, 0.2, 0.2, 0.2]))\n",
      "# Featureknoten\n",
      "nodeBildschirm = (\"bildschirm\", [\"ja\", \"nein\"], numpy.array([[0.01, 0.99], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.05, 0.95]]))\n",
      "nodeAntrieb = (\"antrieb\", [\"stromnetz\", \"akku\", \"hybrid\"], numpy.array([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]))\n",
      "nodeInternet = (\"internet\", [\"ja\", \"nein\"], numpy.array([[1.0, 0.0], [0.9, 0.1], [0.8, 0.2], [0.5, 0.5], [0.01, 0.99]]))\n",
      "nodeEinsatz = (\"einsatz\", [\"buero\", \"heim\", \"mobil\"], numpy.array([[0.98, 0.02, 0.0], [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], [0.05, 0.35, 0.6], [0.0, 1.0, 0.0], [0.02, 0.8, 0.18]]))\n",
      "nodeFarbe = (\"farbe\", [\"schwarz\", \"grau\", \"blau\", \"gruen\"], numpy.array([ [0.5, 0.5, 0.0, 0.0], [0.6, 0.3, 0.05, 0.05], [0.3, 0.2, 0.3, 0.2], [0.7, 0.25, 0.05, 0.0], [0.25, 0.25, 0.25, 0.25]]))\n",
      "\n",
      "# Knoten dem Klassifikator hinzuf\u00fcgen\n",
      "nb.rootNode = rootNode\n",
      "nb.featureNodes.append(nodeBildschirm)\n",
      "nb.featureNodes.append(nodeAntrieb)\n",
      "nb.featureNodes.append(nodeInternet)\n",
      "nb.featureNodes.append(nodeEinsatz)\n",
      "nb.featureNodes.append(nodeFarbe)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Beispiel 1: Ohne Evidenz</h2>\n",
      "Im ersten Anwendungsbeispiel ist die Evidenz noch leer. Die Ausgabe liefert Informationen \u00fcber den Wurzelknoten und \u00fcber den Featureknoten \"einsatz\". Die bedingte Entropie des Featureknoten ist zu interpretieren als die Entropie des Wurzelknoten, wenn der Featureknoten gegeben w\u00e4re."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Keine Evidenz setzen\n",
      "# Harte Evidenz bestimmen\n",
      "evidence = []\n",
      "nb.evidence = evidence\n",
      "\n",
      "print \"++++ Ohne Evidenz ++++\"\n",
      "print nb.rootNode[0], \"(Root)\"\n",
      "print nb.rootNode[1]\n",
      "print nb.calcRootDistribution()\n",
      "print \"Entropie\", nb.getRootEntropy()\n",
      "print \"---- ----\"\n",
      "print nodeEinsatz[0], \"(Feature)\"\n",
      "print nodeEinsatz[1]\n",
      "print nb.calcFeatureDistribution(nodeEinsatz)\n",
      "print \"Bedingte Entropie\", nb.getConditionalEntropy(nodeEinsatz)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Beispiel 2: Harte Evidenz</h2>\n",
      "Das n\u00e4chste Anwendungsbeispiel enth\u00e4lt <i>harte</i> Evidenz f\u00fcr zwei Featureknoten\n",
      "```\n",
      "(bildschirm=ja mit confidence=1.0; farbe=blau mit confidence=1.0)\n",
      "```\n",
      "Im Vergleich zum ersten Beispiel lassen sich Ver\u00e4nderungen in Verteilung und Entropien erkennen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Harte Evidenz bestimmen\n",
      "evidence = []\n",
      "evidence.append([nodeBildschirm, \"ja\", 1.0])\n",
      "evidence.append([nodeFarbe, \"blau\", 1.0])\n",
      "nb.evidence = evidence\n",
      "\n",
      "print \"++++ Mit Evidenz [bildschirm=ja, farbe=blau] ++++\"\n",
      "print nb.rootNode[0], \"(Root)\"\n",
      "print nb.rootNode[1]\n",
      "print nb.calcRootDistribution()\n",
      "print \"Entropie\", nb.getRootEntropy()\n",
      "print \"---- ----\"\n",
      "print nodeEinsatz[0], \"(Feature)\"\n",
      "print nodeEinsatz[1]\n",
      "print nb.calcFeatureDistribution(nodeEinsatz)\n",
      "print \"Bedingte Entropie\", nb.getConditionalEntropy(nodeEinsatz)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Beispiel 3: Weiche Evidenz</h2>\n",
      "Das dritte Anwendungsbeispiel zeigt, wie Unsicherheiten bei der Evidenz angegeben werden k\u00f6nnen:\n",
      "```\n",
      "(bildschirm=ja mit confidence=0.8; farbe=blau mit confidence=0.5)\n",
      "```\n",
      "In der Ausgabe wird ersichtlich, wie die Verteilungen gegen\u00fcber der harten Evidenz des vorherigen Beispiels gegl\u00e4ttet werden und auch die Entropie etwas gr\u00f6\u00dfer ist."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unsichere Evidenz bestimmen\n",
      "evidence = []\n",
      "evidence.append([nodeBildschirm, \"ja\", 0.8])\n",
      "evidence.append([nodeFarbe, \"blau\", 0.5])\n",
      "nb.evidence = evidence\n",
      "\n",
      "print \"++++ Mit unsicherer Evidenz [bildschirm=ja(0.8), farbe=blau(0.5)] ++++\"\n",
      "print nb.rootNode[0], \"(Root)\"\n",
      "print nb.rootNode[1]\n",
      "print nb.calcRootDistribution()\n",
      "print \"Entropie\", nb.getRootEntropy()\n",
      "print \"---- ----\"\n",
      "print nodeEinsatz[0], \"(Feature)\"\n",
      "print nodeEinsatz[1]\n",
      "print nb.calcFeatureDistribution(nodeEinsatz)\n",
      "print \"Bedingte Entropie\", nb.getConditionalEntropy(nodeEinsatz)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}